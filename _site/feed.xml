<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.9.5">Jekyll</generator><link href="https://curtisnewbie.github.io/feed.xml" rel="self" type="application/atom+xml" /><link href="https://curtisnewbie.github.io/" rel="alternate" type="text/html" /><updated>2024-06-26T14:37:38+08:00</updated><id>https://curtisnewbie.github.io/feed.xml</id><title type="html">somewhere in the ocean</title><subtitle>Til the end</subtitle><author><name>Yongjie Zhuang</name></author><entry><title type="html">Learning LangChain</title><link href="https://curtisnewbie.github.io/learning/2024/06/24/learning-langChain.html" rel="alternate" type="text/html" title="Learning LangChain" /><published>2024-06-24T00:00:00+08:00</published><updated>2024-06-24T00:00:00+08:00</updated><id>https://curtisnewbie.github.io/learning/2024/06/24/learning-langChain</id><content type="html" xml:base="https://curtisnewbie.github.io/learning/2024/06/24/learning-langChain.html"><![CDATA[<h2 id="relevant-sites">Relevant Sites</h2>

<ul>
  <li><a href="https://python.langchain.com/v0.2/docs/introduction/">LangChain v0.2 Doc</a></li>
  <li><a href="https://github.com/langchain-ai/langchain">LangChain Github</a></li>
  <li><a href="https://huggingface.co/docs/hub/en/models-downloading">Download HuggingFace Model</a></li>
  <li><a href="https://huggingface.co/microsoft/Phi-3-mini-4k-instruct">HuggingFace - Microsoft/Phi-3-mini-4k-instruct</a></li>
  <li><a href="https://huggingface.co/blog/langchain">Blog - HuggingFace LangChain Partner Package</a></li>
  <li><a href="https://huggingface.co/TinyLlama/TinyLlama-1.1B-Chat-v1.0">HuggingFace - TinyLlama/TinyLlama-1.1B-Chat-v1.0</a></li>
  <li><a href="https://discuss.huggingface.co/t/llama-7b-gpu-memory-requirement/34323/7">HuggingFace Discussion - LLaMA 7B GPU Memory Requirement</a></li>
  <li><a href="https://huggingface.co/docs/hub/en/models-downloading">HuggingFace - Download Modesl</a></li>
  <li><a href="https://python.langchain.com/v0.2/docs/tutorials/chatbot/">LangChain - Chatbot</a></li>
  <li><a href="https://python.langchain.com/v0.2/docs/tutorials/qa_chat_history/">LangChain - Conversational RAG</a></li>
  <li><a href="https://python.langchain.com/v0.2/docs/tutorials/rag/">LangChain - Build a Retrieval Augmented Generation (RAG) App</a></li>
  <li><a href="https://python.langchain.com/v0.2/docs/integrations/vectorstores/chroma/">LangChain - Chroma (Vector Store)</a></li>
</ul>

<h2 id="getting-started">Getting Started</h2>

<p>Install langchain</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>python3 <span class="nt">-m</span> pip <span class="nb">install </span>langchain
</code></pre></div></div>

<p>Setup langsmith (https://smith.langchain.com/), but it’s not really needed, we may well just skip this.</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">export </span><span class="nv">LANGCHAIN_TRACING_V2</span><span class="o">=</span><span class="s2">"true"</span>
<span class="nb">export </span><span class="nv">LANGCHAIN_API_KEY</span><span class="o">=</span><span class="s2">"..."</span>
</code></pre></div></div>

<p>Use LangChain with HuggingFace</p>

<ul>
  <li>https://python.langchain.com/v0.2/docs/integrations/platforms/huggingface/</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>python3 <span class="nt">-m</span> pip <span class="nb">install </span>langchain-huggingface
python3 <span class="nt">-m</span> pip <span class="nb">install</span> <span class="nt">--upgrade</span> <span class="nt">--quiet</span>  transformers <span class="nt">--quiet</span>
</code></pre></div></div>

<p>Load the HuggingFace model locally (TinyLlama/TinyLlama-1.1B-Chat-v1.0), it’s a 1.1b model, I am running it on Macbook Pro M2 16GB. My laptop cannot handle Model with over 3b parameters.</p>

<div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">langchain_huggingface</span> <span class="kn">import</span> <span class="n">HuggingFacePipeline</span>

<span class="n">hf</span> <span class="o">=</span> <span class="n">HuggingFacePipeline</span><span class="p">.</span><span class="n">from_model_id</span><span class="p">(</span>
    <span class="n">model_id</span><span class="o">=</span><span class="s">"TinyLlama/TinyLlama-1.1B-Chat-v1.0"</span><span class="p">,</span>
    <span class="n">task</span><span class="o">=</span><span class="s">"text-generation"</span><span class="p">,</span>
    <span class="n">pipeline_kwargs</span><span class="o">=</span><span class="p">{</span><span class="s">"max_new_tokens"</span><span class="p">:</span> <span class="mi">150</span><span class="p">},</span>
<span class="p">)</span>
</code></pre></div></div>

<p>Task is what the model can handle. In this case, we are using a <code class="language-plaintext highlighter-rouge">text-generation</code> model. Which task should we specify depends on what we are doing, a model may be capable of multiple tasks.</p>

<p><img src="/assets/images/hugging-face-search-task.png" alt="assets/images/hugging-face-search-task.png" /></p>

<blockquote>
  <p>Searching models based on tasks on HuggingFace.</p>
</blockquote>

<p>Create Prompt Template (will get much better response):</p>

<div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">langchain_core.prompts</span> <span class="kn">import</span> <span class="n">PromptTemplate</span>

<span class="c1"># prompt template
</span><span class="n">template</span> <span class="o">=</span> <span class="s">"""Question: {question}

Answer: Let's think step by step."""</span>
<span class="n">prompt</span> <span class="o">=</span> <span class="n">PromptTemplate</span><span class="p">.</span><span class="n">from_template</span><span class="p">(</span><span class="n">template</span><span class="p">)</span>

<span class="c1"># bind local langchain to the prompt
</span><span class="n">chain</span> <span class="o">=</span> <span class="n">prompt</span> <span class="o">|</span> <span class="n">hf</span><span class="p">.</span><span class="n">bind</span><span class="p">()</span>

<span class="n">q</span> <span class="o">=</span> <span class="s">"How to brew coffee?"</span>
<span class="k">print</span><span class="p">(</span><span class="n">chain</span><span class="p">.</span><span class="n">invoke</span><span class="p">({</span><span class="s">"question"</span><span class="p">:</span> <span class="n">q</span><span class="p">}))</span>
</code></pre></div></div>

<p>We can also invoke the model directly without PromptTemplate, but the response is worse:</p>

<div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">print</span><span class="p">(</span><span class="n">hf</span><span class="p">.</span><span class="n">invoke</span><span class="p">(</span><span class="s">"How to brew coffee?"</span><span class="p">))</span>
</code></pre></div></div>

<p>A working example:</p>

<p>gist: https://gist.github.com/CurtisNewbie/2b25f811b5b177548207488b2b409dbf</p>

<div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">langchain_core.prompts</span> <span class="kn">import</span> <span class="n">PromptTemplate</span>
<span class="kn">import</span> <span class="nn">sys</span>
<span class="kn">import</span> <span class="nn">readline</span>
<span class="kn">from</span> <span class="nn">langchain_huggingface</span> <span class="kn">import</span> <span class="n">HuggingFacePipeline</span>

<span class="n">hf</span> <span class="o">=</span> <span class="n">HuggingFacePipeline</span><span class="p">.</span><span class="n">from_model_id</span><span class="p">(</span>
    <span class="n">model_id</span><span class="o">=</span><span class="s">"TinyLlama/TinyLlama-1.1B-Chat-v1.0"</span><span class="p">,</span>
    <span class="n">task</span><span class="o">=</span><span class="s">"text-generation"</span><span class="p">,</span>
    <span class="n">pipeline_kwargs</span><span class="o">=</span><span class="p">{</span>
        <span class="s">"max_new_tokens"</span><span class="p">:</span> <span class="mi">150</span><span class="p">,</span>
        <span class="s">"temperature"</span><span class="p">:</span> <span class="mf">0.7</span><span class="p">,</span>
        <span class="s">"top_k"</span><span class="p">:</span> <span class="mi">50</span><span class="p">,</span>
        <span class="s">"top_p"</span><span class="p">:</span> <span class="mf">0.95</span><span class="p">,</span>
        <span class="s">"do_sample"</span><span class="p">:</span> <span class="bp">True</span><span class="p">,</span>
    <span class="p">},</span>
<span class="p">)</span>

<span class="n">template</span> <span class="o">=</span> <span class="s">"""Question: {question}

Answer: Let's think step by step."""</span>
<span class="n">prompt</span> <span class="o">=</span> <span class="n">PromptTemplate</span><span class="p">.</span><span class="n">from_template</span><span class="p">(</span><span class="n">template</span><span class="p">)</span>

<span class="n">chain</span> <span class="o">=</span> <span class="n">prompt</span> <span class="o">|</span> <span class="n">hf</span><span class="p">.</span><span class="n">bind</span><span class="p">()</span>

<span class="k">while</span> <span class="bp">True</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="k">print</span><span class="p">(</span><span class="s">"Enter your question:"</span><span class="p">)</span>
        <span class="n">q</span> <span class="o">=</span> <span class="n">sys</span><span class="p">.</span><span class="n">stdin</span><span class="p">.</span><span class="n">readline</span><span class="p">().</span><span class="n">strip</span><span class="p">()</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">q</span><span class="p">:</span> <span class="k">continue</span>
        <span class="n">resp</span> <span class="o">=</span> <span class="n">chain</span><span class="p">.</span><span class="n">invoke</span><span class="p">({</span><span class="s">"question"</span><span class="p">:</span> <span class="n">q</span><span class="p">})</span>
        <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"</span><span class="se">\n\n</span><span class="s">&gt; model: '</span><span class="si">{</span><span class="n">resp</span><span class="si">}</span><span class="s">'</span><span class="se">\n</span><span class="s">"</span><span class="p">)</span>

    <span class="k">except</span> <span class="nb">InterruptedError</span><span class="p">:</span>
        <span class="n">sys</span><span class="p">.</span><span class="nb">exit</span><span class="p">()</span>
    <span class="k">except</span> <span class="nb">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"Exception caught </span><span class="si">{</span><span class="n">e</span><span class="si">}</span><span class="s">"</span><span class="p">)</span>
</code></pre></div></div>

<p>If the model supports streaming, we can change the code like the following, the model doesn’t support streaming then:</p>

<div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">for</span> <span class="n">chunk</span> <span class="ow">in</span> <span class="n">chain</span><span class="p">.</span><span class="n">stream</span><span class="p">({</span><span class="s">"question"</span><span class="p">:</span> <span class="n">q</span><span class="p">}):</span>
    <span class="k">print</span><span class="p">(</span><span class="n">chunk</span><span class="p">,</span> <span class="n">flush</span><span class="o">=</span><span class="bp">True</span><span class="p">)</span>
</code></pre></div></div>

<h2 id="retrieval-augmented-generation-rag">Retrieval Augmented Generation (RAG)</h2>

<ul>
  <li><a href="https://python.langchain.com/v0.2/docs/tutorials/rag/">LangChain - Build a Retrieval Augmented Generation (RAG) App</a></li>
  <li><a href="https://python.langchain.com/v0.2/docs/integrations/vectorstores/chroma/">LangChain - Chroma (Vector Store)</a></li>
</ul>

<p>RAG is a way to connect LLM model with external sources. In LangChain’s RAG tutorial, an OpenAI model is used and connected to a online document parsed using bs4.</p>

<p>In essence, RAG involves indexing the data (documents), storing the indexes in vector database, and retrieving the context from the vector database (based on similarity,
i.e., Similarity Search) for the question, and finally adding the context to the prompt that is passed to the LLM model.</p>

<p>The following images are from LangChain.</p>

<p><img src="https://python.langchain.com/v0.2/assets/images/rag_indexing-8160f90a90a33253d0154659cf7d453f.png" height="400px" />
<img src="https://python.langchain.com/v0.2/assets/images/rag_retrieval_generation-1046a4668d6bb08786ef73c56d4f228a.png" height="400px" /></p>

<p>Install relevant dependencies. Chroma is a vector database.</p>

<div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">python3</span> <span class="o">-</span><span class="n">m</span> <span class="n">pip</span> <span class="n">install</span> <span class="n">langchain</span> <span class="n">langchain_community</span> <span class="n">langchain_chroma</span>
</code></pre></div></div>

<p>First of all, we create a LangChain pipeline for the model:</p>

<div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">langchain_core.prompts</span> <span class="kn">import</span> <span class="n">PromptTemplate</span>
<span class="kn">import</span> <span class="nn">re</span>
<span class="kn">import</span> <span class="nn">traceback</span>
<span class="kn">import</span> <span class="nn">sys</span>
<span class="kn">import</span> <span class="nn">readline</span>
<span class="kn">from</span> <span class="nn">langchain_huggingface</span> <span class="kn">import</span> <span class="n">HuggingFacePipeline</span>

<span class="c1"># template = """Question: {question}
</span>
<span class="c1"># Answer: Let's think step by step."""
</span>
<span class="n">max_new_tokens</span><span class="o">=</span><span class="mi">300</span>
<span class="n">task</span><span class="o">=</span><span class="s">"text-generation"</span>
<span class="n">model</span><span class="o">=</span><span class="s">"TinyLlama/TinyLlama-1.1B-Chat-v1.0"</span>

<span class="n">hf</span> <span class="o">=</span> <span class="n">HuggingFacePipeline</span><span class="p">.</span><span class="n">from_model_id</span><span class="p">(</span>
    <span class="n">model_id</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
    <span class="n">task</span><span class="o">=</span><span class="n">task</span><span class="p">,</span>
    <span class="n">pipeline_kwargs</span><span class="o">=</span><span class="p">{</span>
        <span class="s">"max_new_tokens"</span><span class="p">:</span> <span class="n">max_new_tokens</span><span class="p">,</span>
        <span class="s">"temperature"</span><span class="p">:</span> <span class="mf">0.5</span><span class="p">,</span>
        <span class="s">"top_k"</span><span class="p">:</span> <span class="mi">50</span><span class="p">,</span>
        <span class="s">"top_p"</span><span class="p">:</span> <span class="mf">0.95</span><span class="p">,</span>
        <span class="s">"do_sample"</span><span class="p">:</span> <span class="bp">True</span><span class="p">,</span>
    <span class="p">},</span>
<span class="p">)</span>
</code></pre></div></div>

<p>Import DocumentLoader to load external documents. Import Splitter to break documents into chunks. Import Embeddings to create a vector representation of text that is stored in a vector database.
In the following code, the retriever is created from the vector database. Retriever is simply a concept that accepts a string query and returns a list of documents,
in this case, it’s doing similarity search based on the question asked.</p>

<div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">langchain_chroma</span> <span class="kn">import</span> <span class="n">Chroma</span>
<span class="kn">from</span> <span class="nn">langchain_community.document_loaders</span> <span class="kn">import</span> <span class="n">TextLoader</span>
<span class="kn">from</span> <span class="nn">langchain_text_splitters</span> <span class="kn">import</span> <span class="n">CharacterTextSplitter</span>
<span class="kn">from</span> <span class="nn">langchain_community.embeddings.sentence_transformer</span> <span class="kn">import</span> <span class="n">SentenceTransformerEmbeddings</span>
<span class="kn">from</span> <span class="nn">langchain_core.runnables</span> <span class="kn">import</span> <span class="n">RunnablePassthrough</span>

<span class="c1"># load the local document
</span><span class="n">files</span> <span class="o">=</span> <span class="p">[</span><span class="s">"about_onecafe.txt"</span><span class="p">]</span>
<span class="n">documents</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">files</span><span class="p">:</span> <span class="n">documents</span><span class="p">.</span><span class="n">extend</span><span class="p">(</span><span class="n">TextLoader</span><span class="p">(</span><span class="n">f</span><span class="p">).</span><span class="n">load</span><span class="p">())</span>

<span class="c1"># split documents into chunks
</span><span class="n">text_splitter</span> <span class="o">=</span> <span class="n">CharacterTextSplitter</span><span class="p">(</span><span class="n">chunk_size</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">chunk_overlap</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">docs</span> <span class="o">=</span> <span class="n">text_splitter</span><span class="p">.</span><span class="n">split_documents</span><span class="p">(</span><span class="n">documents</span><span class="p">)</span>

<span class="c1"># create Embedding function to convert each piece of text to vector
</span><span class="n">embed</span> <span class="o">=</span> <span class="n">SentenceTransformerEmbeddings</span><span class="p">(</span><span class="n">model_name</span><span class="o">=</span><span class="n">model</span><span class="p">)</span>

<span class="c1"># store documents into Chroma (in memory)
</span><span class="n">vec</span> <span class="o">=</span> <span class="n">Chroma</span><span class="p">.</span><span class="n">from_documents</span><span class="p">(</span><span class="n">docs</span><span class="p">,</span> <span class="n">embed</span><span class="p">)</span>

<span class="c1"># create retriever from the vector database
</span><span class="n">retriever</span> <span class="o">=</span> <span class="n">vec</span><span class="p">.</span><span class="n">as_retriever</span><span class="p">(</span><span class="n">search_kwargs</span><span class="o">=</span><span class="p">{</span><span class="s">"k"</span><span class="p">:</span> <span class="mi">1</span><span class="p">})</span> <span class="c1"># default: k is 4
</span></code></pre></div></div>

<p>With all the Loader, Splitter, Embeddings, Vector Database and Retriever setup, we can construct a chain that automatically complete the context for the LLM model.
The prompt template is slightly different, it now contains a context section for the LLM model. The content of <code class="language-plaintext highlighter-rouge">{context}</code> actually comes from the vector database
using the Retriever that we just created.
The <code class="language-plaintext highlighter-rouge">RunnablePassthrough()</code> does nothing, it just passes the query to <code class="language-plaintext highlighter-rouge">{question}</code> section.</p>

<div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">format_docs</span><span class="p">(</span><span class="n">docs</span><span class="p">):</span>
    <span class="k">return</span> <span class="s">"</span><span class="se">\n\n</span><span class="s">"</span><span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="n">doc</span><span class="p">.</span><span class="n">page_content</span> <span class="k">for</span> <span class="n">doc</span> <span class="ow">in</span> <span class="n">docs</span><span class="p">)</span>

<span class="n">template</span> <span class="o">=</span> <span class="s">"""You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.

Question: {question}

Context: {context}

Answer:"""</span>
<span class="n">prompt</span> <span class="o">=</span> <span class="n">PromptTemplate</span><span class="p">.</span><span class="n">from_template</span><span class="p">(</span><span class="n">template</span><span class="p">)</span>

<span class="n">chain</span> <span class="o">=</span> <span class="p">(</span>
    <span class="p">{</span><span class="s">"context"</span><span class="p">:</span> <span class="n">retriever</span> <span class="o">|</span> <span class="n">format_docs</span><span class="p">,</span> <span class="s">"question"</span><span class="p">:</span> <span class="n">RunnablePassthrough</span><span class="p">()}</span>
    <span class="o">|</span> <span class="n">prompt</span>
    <span class="o">|</span> <span class="n">hf</span><span class="p">.</span><span class="n">bind</span><span class="p">()</span>
<span class="p">)</span>
</code></pre></div></div>

<p>Finally, we just invoke the chain with our question:</p>

<div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">print</span><span class="p">(</span><span class="n">resp</span> <span class="o">=</span> <span class="n">chain</span><span class="p">.</span><span class="n">invoke</span><span class="p">(</span><span class="s">"What is LLM model?"</span><span class="p">))</span>
</code></pre></div></div>

<p>A working example is available in Gist: https://gist.github.com/CurtisNewbie/4037a5c0c924b51ddcf4aa5c99f8590b</p>

<div class="language-py highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">langchain_core.prompts</span> <span class="kn">import</span> <span class="n">PromptTemplate</span>
<span class="kn">import</span> <span class="nn">re</span>
<span class="kn">import</span> <span class="nn">traceback</span>
<span class="kn">import</span> <span class="nn">sys</span>
<span class="kn">import</span> <span class="nn">readline</span>
<span class="kn">from</span> <span class="nn">langchain_huggingface</span> <span class="kn">import</span> <span class="n">HuggingFacePipeline</span>

<span class="n">max_new_tokens</span><span class="o">=</span><span class="mi">300</span>
<span class="n">task</span><span class="o">=</span><span class="s">"text-generation"</span>
<span class="n">model</span><span class="o">=</span><span class="s">"TinyLlama/TinyLlama-1.1B-Chat-v1.0"</span>

<span class="n">hf</span> <span class="o">=</span> <span class="n">HuggingFacePipeline</span><span class="p">.</span><span class="n">from_model_id</span><span class="p">(</span>
    <span class="n">model_id</span><span class="o">=</span><span class="n">model</span><span class="p">,</span>
    <span class="n">task</span><span class="o">=</span><span class="n">task</span><span class="p">,</span>
    <span class="n">pipeline_kwargs</span><span class="o">=</span><span class="p">{</span>
        <span class="s">"max_new_tokens"</span><span class="p">:</span> <span class="n">max_new_tokens</span><span class="p">,</span>
        <span class="s">"temperature"</span><span class="p">:</span> <span class="mf">0.5</span><span class="p">,</span>
        <span class="s">"top_k"</span><span class="p">:</span> <span class="mi">50</span><span class="p">,</span>
        <span class="s">"top_p"</span><span class="p">:</span> <span class="mf">0.95</span><span class="p">,</span>
        <span class="s">"do_sample"</span><span class="p">:</span> <span class="bp">True</span><span class="p">,</span>
    <span class="p">},</span>
<span class="p">)</span>

<span class="kn">from</span> <span class="nn">langchain_chroma</span> <span class="kn">import</span> <span class="n">Chroma</span>
<span class="kn">from</span> <span class="nn">langchain_community.document_loaders</span> <span class="kn">import</span> <span class="n">TextLoader</span>
<span class="kn">from</span> <span class="nn">langchain_text_splitters</span> <span class="kn">import</span> <span class="n">CharacterTextSplitter</span>
<span class="kn">from</span> <span class="nn">langchain_community.embeddings.sentence_transformer</span> <span class="kn">import</span> <span class="n">SentenceTransformerEmbeddings</span>
<span class="kn">from</span> <span class="nn">langchain_core.runnables</span> <span class="kn">import</span> <span class="n">RunnablePassthrough</span>

<span class="c1"># load the document and split it into chunks
</span><span class="n">files</span> <span class="o">=</span> <span class="p">[</span><span class="s">"about_onecafe.txt"</span><span class="p">]</span>
<span class="n">documents</span> <span class="o">=</span> <span class="p">[]</span>
<span class="k">for</span> <span class="n">f</span> <span class="ow">in</span> <span class="n">files</span><span class="p">:</span>
    <span class="n">documents</span><span class="p">.</span><span class="n">extend</span><span class="p">(</span><span class="n">TextLoader</span><span class="p">(</span><span class="n">f</span><span class="p">).</span><span class="n">load</span><span class="p">())</span>

<span class="c1"># split it into chunks
</span><span class="n">text_splitter</span> <span class="o">=</span> <span class="n">CharacterTextSplitter</span><span class="p">(</span><span class="n">chunk_size</span><span class="o">=</span><span class="mi">1000</span><span class="p">,</span> <span class="n">chunk_overlap</span><span class="o">=</span><span class="mi">0</span><span class="p">)</span>
<span class="n">docs</span> <span class="o">=</span> <span class="n">text_splitter</span><span class="p">.</span><span class="n">split_documents</span><span class="p">(</span><span class="n">documents</span><span class="p">)</span>
<span class="c1"># print("&gt;&gt; docs", docs)
</span>
<span class="c1"># create the open-source embedding function
</span><span class="n">embed</span> <span class="o">=</span> <span class="n">SentenceTransformerEmbeddings</span><span class="p">(</span><span class="n">model_name</span><span class="o">=</span><span class="n">model</span><span class="p">)</span>

<span class="c1"># load it into Chroma
</span><span class="n">vec</span> <span class="o">=</span> <span class="n">Chroma</span><span class="p">.</span><span class="n">from_documents</span><span class="p">(</span><span class="n">docs</span><span class="p">,</span> <span class="n">embed</span><span class="p">)</span>
<span class="n">reti</span> <span class="o">=</span> <span class="n">vec</span><span class="p">.</span><span class="n">as_retriever</span><span class="p">(</span><span class="n">search_kwargs</span><span class="o">=</span><span class="p">{</span><span class="s">"k"</span><span class="p">:</span> <span class="mi">1</span><span class="p">})</span> <span class="c1"># default: k is 4
</span>
<span class="k">def</span> <span class="nf">format_docs</span><span class="p">(</span><span class="n">docs</span><span class="p">):</span>
    <span class="k">return</span> <span class="s">"</span><span class="se">\n\n</span><span class="s">"</span><span class="p">.</span><span class="n">join</span><span class="p">(</span><span class="n">doc</span><span class="p">.</span><span class="n">page_content</span> <span class="k">for</span> <span class="n">doc</span> <span class="ow">in</span> <span class="n">docs</span><span class="p">)</span>

<span class="n">template</span> <span class="o">=</span> <span class="s">"""You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.

Question: {question}

Context: {context}

Answer:"""</span>
<span class="n">prompt</span> <span class="o">=</span> <span class="n">PromptTemplate</span><span class="p">.</span><span class="n">from_template</span><span class="p">(</span><span class="n">template</span><span class="p">)</span>

<span class="n">chain</span> <span class="o">=</span> <span class="p">(</span>
    <span class="p">{</span><span class="s">"context"</span><span class="p">:</span> <span class="n">reti</span> <span class="o">|</span> <span class="n">format_docs</span><span class="p">,</span> <span class="s">"question"</span><span class="p">:</span> <span class="n">RunnablePassthrough</span><span class="p">()}</span>
    <span class="o">|</span> <span class="n">prompt</span>
    <span class="o">|</span> <span class="n">hf</span><span class="p">.</span><span class="n">bind</span><span class="p">()</span>
<span class="p">)</span>

<span class="k">print</span><span class="p">(</span><span class="s">"</span><span class="se">\n\n</span><span class="s">"</span><span class="p">)</span>
<span class="n">ans_pat</span> <span class="o">=</span> <span class="s">"^.*Answer: *(.*)$"</span>
<span class="k">while</span> <span class="bp">True</span><span class="p">:</span>
    <span class="k">try</span><span class="p">:</span>
        <span class="k">print</span><span class="p">(</span><span class="s">"Enter your question:"</span><span class="p">)</span>
        <span class="n">q</span> <span class="o">=</span> <span class="n">sys</span><span class="p">.</span><span class="n">stdin</span><span class="p">.</span><span class="n">readline</span><span class="p">().</span><span class="n">strip</span><span class="p">()</span>
        <span class="k">while</span> <span class="ow">not</span> <span class="n">q</span><span class="p">:</span> <span class="k">continue</span>

        <span class="n">resp</span> <span class="o">=</span> <span class="n">chain</span><span class="p">.</span><span class="n">invoke</span><span class="p">(</span><span class="n">q</span><span class="p">)</span>
        <span class="n">m</span> <span class="o">=</span> <span class="n">re</span><span class="p">.</span><span class="n">search</span><span class="p">(</span><span class="n">ans_pat</span><span class="p">,</span> <span class="n">resp</span><span class="p">,</span> <span class="n">re</span><span class="p">.</span><span class="n">DOTALL</span><span class="p">)</span>
        <span class="n">ans</span> <span class="o">=</span> <span class="n">resp</span>
        <span class="k">if</span> <span class="n">m</span><span class="p">:</span> <span class="n">ans</span> <span class="o">=</span> <span class="n">m</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span>

        <span class="k">print</span><span class="p">(</span><span class="sa">f</span><span class="s">"</span><span class="se">\n\n</span><span class="s">&gt; AI: '</span><span class="si">{</span><span class="n">ans</span><span class="si">}</span><span class="s">'</span><span class="se">\n</span><span class="s">"</span><span class="p">)</span>

    <span class="k">except</span> <span class="nb">InterruptedError</span><span class="p">:</span>
        <span class="n">sys</span><span class="p">.</span><span class="nb">exit</span><span class="p">()</span>
    <span class="k">except</span> <span class="nb">Exception</span> <span class="k">as</span> <span class="n">e</span><span class="p">:</span>
        <span class="k">print</span><span class="p">(</span><span class="s">"Exception caught"</span><span class="p">,</span> <span class="n">e</span><span class="p">)</span>
        <span class="n">traceback</span><span class="p">.</span><span class="n">print_exc</span><span class="p">()</span>
</code></pre></div></div>

<h2 id="conceptual-guide">Conceptual Guide</h2>

<ul>
  <li><a href="https://python.langchain.com/v0.2/docs/concepts">LangChain - Conceptual Guide</a></li>
</ul>

<p>TODO:</p>

<h2 id="conversational-rag">Conversational RAG</h2>

<ul>
  <li><a href="https://python.langchain.com/v0.2/docs/tutorials/qa_chat_history/">LangChain - Conversational RAG</a></li>
</ul>

<p>TODO: How to remmeber the chat history</p>

<h2 id="terminology">Terminology</h2>

<ul>
  <li><code class="language-plaintext highlighter-rouge">HF Format</code>: Hugging Face Format</li>
</ul>]]></content><author><name>Yongjie Zhuang</name></author><category term="Learning" /><summary type="html"><![CDATA[Relevant Sites]]></summary></entry><entry><title type="html">moon - the private cloud</title><link href="https://curtisnewbie.github.io/projects/2024/06/03/moon-the-private-cloud.html" rel="alternate" type="text/html" title="moon - the private cloud" /><published>2024-06-03T18:00:00+08:00</published><updated>2024-06-03T18:00:00+08:00</updated><id>https://curtisnewbie.github.io/projects/2024/06/03/moon-the-private-cloud</id><content type="html" xml:base="https://curtisnewbie.github.io/projects/2024/06/03/moon-the-private-cloud.html"><![CDATA[<p>The moon project is self-hosted private cloud that consists of a set of backend and frontend services that I maintain in my spare time.</p>

<p>These can be found in the following repositories:</p>

<ul>
  <li><a href="https://github.com/curtisnewbie/user-vault">curtisnewbie/user-vault</a></li>
  <li><a href="https://github.com/curtisnewbie/vfm">curtisnewbie/vfm</a></li>
  <li><a href="https://github.com/curtisnewbie/mini-fstore">curtisnewbie/mini-fstore</a></li>
  <li><a href="https://github.com/curtisnewbie/logbot">curtisnewbie/logbot</a></li>
  <li><a href="https://github.com/curtisnewbie/gatekeeper">curtisnewbie/gatekeeper</a></li>
  <li><a href="https://github.com/curtisnewbie/moon">curtisnewbie/moon</a></li>
</ul>

<!-- TODO -->]]></content><author><name>Yongjie Zhuang</name></author><category term="Projects" /><summary type="html"><![CDATA[The moon project is self-hosted private cloud that consists of a set of backend and frontend services that I maintain in my spare time.]]></summary></entry><entry><title type="html">Interesting Resources</title><link href="https://curtisnewbie.github.io/learning/2024/04/15/interesting-resources.html" rel="alternate" type="text/html" title="Interesting Resources" /><published>2024-04-15T20:00:00+08:00</published><updated>2024-04-15T20:00:00+08:00</updated><id>https://curtisnewbie.github.io/learning/2024/04/15/interesting-resources</id><content type="html" xml:base="https://curtisnewbie.github.io/learning/2024/04/15/interesting-resources.html"><![CDATA[<p>Interesting papers, books and websites are listed here.</p>

<h3 id="papers">Papers</h3>

<ul>
  <li><a href="https://www.allthingsdistributed.com/files/amazon-dynamo-sosp2007.pdf">Dynamo: Amazon’s Highly Available Key-value Store</a></li>
</ul>

<h3 id="blogs-presentations-and-docs">Blogs, Presentations and Docs</h3>

<ul>
  <li><a href="https://ebpf-go.dev/">eBPF Library for Go</a></li>
  <li><a href="https://ebpf.io/what-is-ebpf">What is eBPF</a></li>
  <li><a href="https://www.infoq.com/presentations/shopify-architecture-flash-sale/">Shopify’s Architecture to Handle the World’s Biggest Flash Sales</a></li>
  <li><a href="https://martinfowler.com/articles/lmax.html">Martin Fowler - The LMAX Architecture</a></li>
  <li><a href="https://lmax-exchange.github.io/disruptor/">Github Page - LMAX Disruptor</a></li>
  <li><a href="https://dave.cheney.net/2013/06/02/why-is-a-goroutines-stack-infinite">Dave Cheney - Why is a Goroutine’s stack infinite?</a></li>
  <li><a href="https://docs.google.com/document/u/0/d/1yIAYmbvL3JxOKOjuCyon7JhW4cSv1wy5hC0ApeGMV9s/pub?pli=1">Go channels on steroids</a></li>
  <li><a href="https://benchmarksgame-team.pages.debian.net/benchmarksgame/index.html">The Computer Language Benchmark Game</a></li>
  <li><a href="https://docs.oracle.com/en/java/javase/20/gctuning/index.html#GUID-0394E76A-1A8F-425E-A0D0-B48A3DC82B42">jdk20 - HotSpot Virtual Machine Garbage Collection Tuning Guide</a></li>
  <li><a href="https://docs.oracle.com/javase/8/docs/technotes/guides/troubleshoot/toc.html">jdk8 - Java Platform, Standard Edition Troubleshooting Guide</a></li>
  <li><a href="https://tschatzl.github.io/2022/08/04/concurrent-marking.html">Concurrent Marking in G1</a></li>
  <li><a href="https://landontclipp.github.io/blog/2023/07/15/analyzing-go-heap-escapes/#use-of-reflection">Analyzing Go Heap Escapes</a></li>
  <li><a href="https://chris124567.github.io/2021-06-21-go-performance/">Reducing Memory Allocations in Golang</a></li>
  <li><a href="https://github.com/redis/redis-specifications/blob/master/protocol/RESP2.md">Github - RESP2 Protocol Specification</a></li>
  <li><a href="https://medium.com/@chenymj23/diving-into-golang-how-does-it-effectively-wrap-the-functionality-of-epoll-26065f0654ba">Diving into Golang: How does it effectively wrap the functionality of epoll?</a></li>
  <li><a href="https://blog.mike.norgate.xyz/unlocking-go-slice-performance-navigating-sync-pool-for-enhanced-efficiency-7cb63b0b453e">Unlocking Go Slice Performance: Navigating sync.Pool for Enhanced Efficiency</a></li>
  <li><a href="https://gist.github.com/JBlond/2fea43a3049b38287e5e9cefc87b2124">JBlond Gist - Bash Colors</a></li>
  <li><a href="https://k3s.io/">k3s</a></li>
  <li><a href="https://blog.ragozin.info/2011/06/understanding-gc-pauses-in-jvm-hotspots.html">Understanding GC pauses in JVM, HotSpot’s minor GC (2011)</a></li>
  <li><a href="https://netflix.github.io/dgs/">Netflix DGS Framework</a></li>
  <li><a href="https://github.com/Netflix/conductor">Netflix Conductor</a></li>
  <li><a href="https://github.com/conductor-sdk/conductor-examples/tree/main">Conductor-sdk</a></li>
  <li><a href="https://orkes.io/content/">Orkes - Conductor</a></li>
  <li><a href="https://shipilev.net/jvm/anatomy-quarks/">JVM Anatomy Quarks</a></li>
  <li><a href="https://netflixtechblog.com/bending-pause-times-to-your-will-with-generational-zgc-256629c9386b">Netflix Technology Blog - Bending pause times to your will with Generational ZGC</a></li>
  <li><a href="https://www.infoq.com/presentations/netflix-java/">InfoQ - How Netflix Really Uses Java</a></li>
  <li><a href="https://go.dev/ref/spec">The Go Programming Language Specification</a></li>
  <li><a href="https://go.dev/doc/effective_go">Effective Go</a></li>
  <li><a href="https://go.dev/ref/mem">Go Memory Model</a></li>
  <li><a href="https://netflixtechblog.com/linux-performance-analysis-in-60-000-milliseconds-accc10403c55">Netflix Technology Blog - Linux Performance Analysis in 60,000 milliseconds</a></li>
  <li><a href="https://www.redhat.com/sysadmin/cgroups-part-one">A Linux sysadmin’s introduction to cgroups</a></li>
  <li><a href="https://www.cs.unh.edu/cnrg/people/gherrin/linux-net.html">Glenn Herrin (2000) Linux IP Networking</a></li>
  <li><a href="https://www.cloudcentric.dev/implementing-a-skip-list-in-go/">Implementing a skip list in go</a></li>
  <li><a href="https://github.com/redis/redis/blob/unstable/src/ziplist.c">ziplist.c source code in github.com/redis</a></li>
  <li><a href="https://eclipsesource.com/blogs/2013/01/21/10-tips-for-using-the-eclipse-memory-analyzer/">10 Tips for using the Eclipse Memory Analyzer</a></li>
  <li><a href="https://tikv.org/deep-dive/key-value-engine/b-tree-vs-lsm/">tikv - B-Tree vs LSM-Tree</a></li>
  <li><a href="https://medium.com/eureka-engineering/understanding-allocations-in-go-stack-heap-memory-9a2631b5035d">Understanding Allocations in Go</a></li>
  <li><a href="https://pkg.go.dev/cmd/trace">golang - cmd/trace</a></li>
  <li><a href="https://medium.com/@ankur_anand/a-visual-guide-to-golang-memory-allocator-from-ground-up-e132258453ed">A visual guide to Go Memory Allocator from scratch</a></li>
  <li><a href="https://java-decompiler.github.io/">Java Decompiler</a></li>
  <li><a href="https://catonmat.net/bash-one-liners-explained-part-one">Bash One-Liners Explained</a></li>
  <li><a href="https://tldp.org/HOWTO/IP-Masquerade-HOWTO/index.html">Linux IP Masquerade HOWTO, David A. Ranch</a></li>
  <li><a href="https://mysql.rjweb.org/doc.php/deletebig">MySQL Big DELETEs</a></li>
  <li><a href="https://research.swtch.com/interfaces">Go Data Structures: Interfaces</a></li>
  <li><a href="https://morsmachine.dk/go-scheduler">The Go Scheduler</a></li>
  <li><a href="https://www.kernel.org/doc/html/latest/index.html">Linux Kernel Documentation</a></li>
</ul>

<h3 id="database-related">Database Related</h3>

<ul>
  <li><a href="https://stackoverflow.com/questions/68443220/how-mvcc-works-with-lock-in-mysql">stackoverflow - how mvcc works with lock in mysql</a></li>
  <li><a href="https://jahfer.com/posts/innodb-locks/">jahfer.com - innodb-locks</a></li>
  <li><a href="https://dev.mysql.com/doc/refman/8.0/en/mysql-upgrade.html">mysql_upgrade tool for MySQL &lt; 8.0.16</a></li>
  <li><a href="https://dev.mysql.com/blog-archive/inplace-upgrade-from-mysql-5-7-to-mysql-8-0/">Inplace Upgrade MySQL 5.7 to 8.0</a></li>
  <li><a href="https://dev.mysql.com/doc/mysql-shell/8.0/en/mysql-shell-utilities-upgrade.html">MySQL Shell Upgrade Checker</a></li>
  <li><a href="https://github.com/dolthub/dolt">github dolthub/dolt</a></li>
  <li><a href="https://github.com/dolthub/go-mysql-server">github dolthub/go-mysql-server</a></li>
  <li><a href="https://github.blog/2018-06-20-mysql-high-availability-at-github/#:~:text=GitHub%20uses%20MySQL%20as%20its,is%20critical%20to%20GitHub's%20operation.">Github Blog - MySQL High Availability at Github</a></li>
  <li><a href="https://dev.mysql.com/doc/index-archive.html">MySQL Server Index Archive</a></li>
  <li><a href="https://dev.mysql.com/doc/dev/mysql-server/latest/">MySQL Server Source Code Documentation</a></li>
  <li><a href="https://dev.mysql.com/blog-archive/hash-join-in-mysql-8/">Hash join in MySQL 8</a></li>
  <li><a href="https://oceanbase.github.io/miniob/miniob-introduction.html">MiniOB Github Page - zh-cn</a></li>
  <li><a href="https://github.com/oceanbase/miniob?tab=readme-ov-file">MiniOB Github - zh-cn</a></li>
  <li><a href="https://github.com/oceanbase/oceanbase">Oceanbase Github</a></li>
  <li><a href="https://en.oceanbase.com/docs/oceanbase-database">Oceanbase Doc</a></li>
  <li><a href="https://use-the-index-luke.com/sql/preface">Use the index, Luke - A Guide to Database Performance for Developers</a></li>
</ul>

<!-- ### Languages -->

<h3 id="other-github-repos">Other Github Repos</h3>

<ul>
  <li><a href="https://github.com/elastic/otel-profiling-agent">elastic/otel-profiling-agent</a></li>
  <li><a href="https://github.com/vadv/gopher-lua-libs">vadv/gopher-lua-libs</a></li>
  <li><a href="https://github.com/yuin/gopher-lua">yuin/gopher-lua</a></li>
  <li><a href="https://github.com/jamiebuilds/the-super-tiny-compiler">jamiebuilds/the-super-tiny-compiler</a></li>
  <li><a href="https://github.com/kjpgit/smallestcsvparser">kjpgit/SmallestCSVParser</a></li>
</ul>

<h2 id="perf">Perf</h2>

<ul>
  <li><a href="https://www.brendangregg.com/flamegraphs.html">Bred Angregg Flame Grphs</a></li>
  <li><a href="https://queue.acm.org/detail.cfm?id=2927301">Acm Queue - The Flame Graph</a></li>
</ul>]]></content><author><name>Yongjie Zhuang</name></author><category term="Learning" /><summary type="html"><![CDATA[Interesting papers, books and websites are listed here.]]></summary></entry><entry><title type="html">Random Ideas</title><link href="https://curtisnewbie.github.io/ideas/2024/04/15/random-ideas.html" rel="alternate" type="text/html" title="Random Ideas" /><published>2024-04-15T19:00:00+08:00</published><updated>2024-04-15T19:00:00+08:00</updated><id>https://curtisnewbie.github.io/ideas/2024/04/15/random-ideas</id><content type="html" xml:base="https://curtisnewbie.github.io/ideas/2024/04/15/random-ideas.html"><![CDATA[<p>List of random ideas:</p>

<ul class="task-list">
  <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled" />Implement a mini version of Git to understand how it works.</li>
  <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled" />Implement a simple B+ tree based database.</li>
  <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled" />Implement a mini-redis using java like the <a href="https://github.com/curtisnewbie/mini-redis">curtisnewbie/mini-redis</a> one in golang.
    <ul>
      <li>Call it mini-jredis maybe, just try to be more familiar with socket programming in java.</li>
    </ul>
  </li>
  <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled" />Have a look at netflix/conductor, understand roughly how it works and implement a mini workflow engine.
    <ul>
      <li>It does seem like a workflow engine is roughly a distributed queue + an orchestrator service + some definitions of worker.</li>
      <li>https://github.com/Netflix/conductor</li>
      <li>https://github.com/conductor-sdk/conductor-examples/tree/main</li>
      <li>https://orkes.io/content/</li>
    </ul>
  </li>
  <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled" />Document how to use pprof in golang.</li>
  <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled" />Write something about jvm performance evaluation. Document all the means to identify performance issue, e.g., CPU/IO/GC and so on.</li>
  <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled" checked="checked" />Implement a simple CI/CD application.
    <ul>
      <li><a href="https://github.com/curtisnewbie/chill">https://github.com/curtisnewbie/chill</a></li>
    </ul>
  </li>
  <li class="task-list-item"><input type="checkbox" class="task-list-item-checkbox" disabled="disabled" />Implement a rule engine.
    <ul>
      <li><a href="https://github.com/curtisnewbie/octopus">https://github.com/curtisnewbie/octopus</a></li>
    </ul>
  </li>
</ul>]]></content><author><name>Yongjie Zhuang</name></author><category term="Ideas" /><summary type="html"><![CDATA[List of random ideas:]]></summary></entry><entry><title type="html">Learning Jekyll</title><link href="https://curtisnewbie.github.io/learning/2024/04/15/learning-jekyll.html" rel="alternate" type="text/html" title="Learning Jekyll" /><published>2024-04-15T13:00:00+08:00</published><updated>2024-04-15T13:00:00+08:00</updated><id>https://curtisnewbie.github.io/learning/2024/04/15/learning-jekyll</id><content type="html" xml:base="https://curtisnewbie.github.io/learning/2024/04/15/learning-jekyll.html"><![CDATA[<p><strong><em>This is my first blog. We are learning Jekyll today, documenting jekyll stuff inside a static site generated by jekyll!</em></strong></p>

<p>The following are useful websites for learning jekyll:</p>

<ul>
  <li>Jekyllrb Official: https://jekyllrb.com/</li>
  <li>Github Page: https://docs.github.com/en/pages/quickstart</li>
</ul>

<h2 id="install-jekyll">Install Jekyll</h2>

<p>To install jekyll on Macos, we will first use brew to install a separate ruby, e.g., ruby@3. Macos has a built-in ruby installed, but we will need root priviliege to install packages, i.e., running ruby commands with sudo, it’s not safe so we won’t do that.</p>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code>brew <span class="nb">install </span>ruby@3
</code></pre></div></div>

<p>After the installation, we export the path to ruby@3. Of course we can run <code class="language-plaintext highlighter-rouge">brew link</code>, but it won’t work because there is already one pre-installed. If you run <code class="language-plaintext highlighter-rouge">brew link</code>, you will see the warning messages.</p>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Warning: Refusing to <span class="nb">link </span>macOS provided/shadowed software: ruby
If you need to have ruby first <span class="k">in </span>your PATH, run:
  <span class="nb">echo</span> <span class="s1">'export PATH="/usr/local/opt/ruby/bin:$PATH"'</span> <span class="o">&gt;&gt;</span> ~/.profile

<span class="c"># ...</span>
</code></pre></div></div>

<p>We can follow it’s recommendation, we export the path in our <code class="language-plaintext highlighter-rouge">~/.profile</code> file or <code class="language-plaintext highlighter-rouge">~/.bashrc</code> file.</p>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">export </span><span class="nv">PATH</span><span class="o">=</span><span class="s2">"/usr/local/opt/ruby/bin:</span><span class="nv">$PATH</span><span class="s2">"</span>
</code></pre></div></div>

<p>Til this point, ruby@3 is successfully installed. You may setup a mirror registry like the following to speed things up a bit. Usually you don’t need to change the sources, unless you are from certain countries like me :D</p>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># setup mirror source for gem</span>
gem sources <span class="nt">--add</span> https://mirrors.tuna.tsinghua.edu.cn/rubygems/ <span class="nt">--remove</span> https://rubygems.org/
</code></pre></div></div>

<p>Then, we will also need to install <code class="language-plaintext highlighter-rouge">bundle</code>, which is a dependency manager for ruby (kinda), as well as <code class="language-plaintext highlighter-rouge">jekyll</code>, the package that we need!</p>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code>gem <span class="nb">install </span>bundler jekyll
</code></pre></div></div>

<p>We can also setup the source address for bundle! And yes, it’s completely optional.</p>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code>bundle config mirror.https://rubygems.org https://mirrors.tuna.tsinghua.edu.cn/rubygems
</code></pre></div></div>

<p>Then we can start following the tutorial and create our first jekyll project.</p>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code>jekyll new my-awesome-site
</code></pre></div></div>

<p>We can <code class="language-plaintext highlighter-rouge">cd</code> into it, and serve the website in dev mode.</p>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code>bundle <span class="nb">exec </span>jekyll serve
</code></pre></div></div>

<p>In the meantime, if you are using ruby@3 like me, for whatever reason, you may see a warning message as follows. I don’t really know what causes it, but it seems like jekyll is actually working fine. I personally believes that it’s related to the version of our dependencies, some stuff may be deprecated.</p>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Deprecation Warning: Using / <span class="k">for </span>division outside of calc<span class="o">()</span> is deprecated and will be removed <span class="k">in </span>Dart Sass 2.0.0.

Recommendation: math.div<span class="o">(</span><span class="nv">$spacing</span><span class="nt">-unit</span>, 2<span class="o">)</span> or calc<span class="o">(</span><span class="nv">$spacing</span><span class="nt">-unit</span> / 2<span class="o">)</span>

More info and automated migrator: https://sass-lang.com/d/slash-div

   ╷
40 │   margin-bottom: <span class="nv">$spacing</span><span class="nt">-unit</span> / 2<span class="p">;</span>
   │                  ^^^^^^^^^^^^^^^^^
   ╵
    ../../../../minima-2.5.1/_sass/minima/_base.scss 40:18  @import
    minima.scss 48:3                                        @import
</code></pre></div></div>

<p>Lukily, I did find a way to fix it (by muting the warning messages, lol).</p>

<p>Inside _config.yml, we add the following properties:</p>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">sass</span><span class="pi">:</span>
  <span class="na">quiet_deps</span><span class="pi">:</span> <span class="no">true</span>
</code></pre></div></div>

<p>Run <code class="language-plaintext highlighter-rouge">jekyll serve</code> again, we will see our beautiful website on <code class="language-plaintext highlighter-rouge">http://localhost:4000</code>.</p>

<h2 id="the-basic">The Basic</h2>

<p>By default jekyll uses theme <code class="language-plaintext highlighter-rouge">minima</code>, you are free to change it.</p>

<p>A jekyll project contains multiple <code class="language-plaintext highlighter-rouge">_***</code> directories. The <code class="language-plaintext highlighter-rouge">_posts</code> directory store the posts you write. The <code class="language-plaintext highlighter-rouge">_site</code> directory stores the static files generated by jekyll, so you will not modify files in this directory.</p>

<p>File <code class="language-plaintext highlighter-rouge">_config.yml</code> includes the basic configuration for your jekyll website. There are also the <code class="language-plaintext highlighter-rouge">about.markdown</code> and <code class="language-plaintext highlighter-rouge">index.markdown</code> files in root directory, you can modify the content of these two files as well as the markdown files in <code class="language-plaintext highlighter-rouge">_posts</code>.</p>

<p>Once you have done writing the content, you can run <code class="language-plaintext highlighter-rouge">jekyll serve</code> to see the latest changes. All the changes are rendered and written to <code class="language-plaintext highlighter-rouge">_site</code> directory.</p>

<p>Most of the cases, you will be modifing files inside <code class="language-plaintext highlighter-rouge">_posts</code> directory. The filename must follow the following convension: <code class="language-plaintext highlighter-rouge">YEAR-MONTH-DAY-title.MARKUP</code>, or else the posts are not displayed on webpage.</p>

<p>e.g.,</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>2024-04-01-learning-go.markdown
2024-04-02-learning-js.markdown
2024-04-03-learning-java.markdown
</code></pre></div></div>

<p>To better understand the file hierarchy, the following is the file tree of a demo project.</p>

<div class="language-sh highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">.</span>
├── 404.html
├── Gemfile
├── Gemfile.lock
├── _config.yml
├── _posts
│   ├── 2024-04-15-learning-jekyll.markdown
├── _site
│   ├── ...
├── about.markdown
└── index.markdown
</code></pre></div></div>

<p>If we want to create a new post, we can just simply copy the existing post file in <code class="language-plaintext highlighter-rouge">_posts</code>, modify the content and that’s it.</p>

<p>E.g., a new file named <code class="language-plaintext highlighter-rouge">2024-04-15-my-first-blog.markdown</code>.</p>

<div class="language-markdown highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nn">---</span>
<span class="na">layout</span><span class="pi">:</span> <span class="s">post</span>
<span class="na">title</span><span class="pi">:</span>  <span class="s2">"</span><span class="s">My</span><span class="nv"> </span><span class="s">First</span><span class="nv"> </span><span class="s">Blog"</span>
<span class="na">date</span><span class="pi">:</span>   <span class="s">2024-04-15 13:00:00 +0800</span>
<span class="na">categories</span><span class="pi">:</span> <span class="s">random stuff</span>
<span class="na">published</span><span class="pi">:</span> <span class="no">true</span>
<span class="nn">---</span>

I am the first blog!
</code></pre></div></div>

<p>That’s it. This should be enough to get started :D</p>

<h2 id="host-jekyll-project-using-github-page">Host Jekyll Project Using Github Page</h2>

<p>Follow guidelines in https://docs.github.com/en/pages/setting-up-a-github-pages-site-with-jekyll/creating-a-github-pages-site-with-jekyll.</p>

<p>Before you push all the changes to upstream, build the jekyll project as follows:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>bundle exec jekyll build
</code></pre></div></div>

<p>Go to github page, in repo’s Settings &gt; Pages, select your branch and root directory, and then save. The github page for your jekyll project will be deployed automatically using github action.</p>]]></content><author><name>Yongjie Zhuang</name></author><category term="Learning" /><summary type="html"><![CDATA[This is my first blog. We are learning Jekyll today, documenting jekyll stuff inside a static site generated by jekyll!]]></summary></entry></feed>